{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import json\n",
    "\n",
    "from bigbench.api import json_task\n",
    "import bigbench.models.huggingface_models as huggingface_models\n",
    "import bigbench.api.model as api_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Types:  ['gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl', 'openai-gpt']\n"
     ]
    }
   ],
   "source": [
    "print('Model Types: ', list(huggingface_models.MODEL_NAMES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec431dafc27f48f3b1309786e289046e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model_type = 'gpt2'\n",
    "model = huggingface_models.BIGBenchHFModel(model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.64976961 -1.36499483 -0.59325869]\n",
      "CPU times: user 1.03 s, sys: 121 ms, total: 1.15 s\n",
      "Wall time: 491 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores = model.cond_log_prob(\n",
    "    inputs=\"What color is grass? Answer:\", \n",
    "    targets=('red', 'blue', 'green')\n",
    "    )\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/task.json') as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_task = json_task.JsonTask(\n",
    "    task_data=data,\n",
    "    shot_list=[0, 1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating deducing_implicit_relations for 0 shots...\n",
      "evaluating deducing_implicit_relations for 1 shots...\n"
     ]
    }
   ],
   "source": [
    "score_data = current_task.evaluate_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ScoreData(score_dict={'multiple_choice_grade': 0.0}, preferred_score='multiple_choice_grade', number_of_shots=0, low_score=0.27777777777777773, high_score=1.0, subtask_description='deducing_implicit_relations'),\n",
       " ScoreData(score_dict={'multiple_choice_grade': 0.5}, preferred_score='multiple_choice_grade', number_of_shots=1, low_score=0.27777777777777773, high_score=1.0, subtask_description='deducing_implicit_relations')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "big_bench",
   "language": "python",
   "name": "big_bench"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
